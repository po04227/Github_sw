{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP(MNIST) with Early Stopping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhUNDrwm4XePQ9Ja5EY11N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/po04227/Github_sw/blob/master/MLP(MNIST)_with_Early_Stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMeDj8wQw7R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import numpy as np\n",
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms9umg9-w-C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "f3f2a28b-7852-4262-c8a2-3f548550cd1a"
      },
      "source": [
        "# MLP Architecture\n",
        "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPpNGgXiw-Ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2a6ed08e-542d-4346-f5b5-54e2b3e87264"
      },
      "source": [
        "# Collect MNIST Data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfLem1T8w-SF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5f94b997-4374-4be0-8b8b-02f2d677c4a2"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV0GD1cDw-Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split train data into train and validation data\n",
        "x_val  = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val  = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kJJbq3Aw-g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7d067182-3b7f-4169-9f6c-631a585ee451"
      },
      "source": [
        "print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n",
        "print(\"every train data is \" + str(x_train.shape[1]) \n",
        "      + \" * \" + str(x_train.shape[2]) + \" image\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data has 50000 samples\n",
            "every train data is 28 * 28 image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zIciG1bw_V9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "33b3d787-a3fe-4321-fbf5-dea57d6f0100"
      },
      "source": [
        "print(\"validation data has \" + str(x_val.shape[0]) + \" samples\")\n",
        "print(\"every train data is \" + str(x_val.shape[1]) \n",
        "      + \" * \" + str(x_train.shape[2]) + \" image\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation data has 10000 samples\n",
            "every train data is 28 * 28 image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLhwJVXVw_c8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "61800864-1927-48c4-88e8-604029882266"
      },
      "source": [
        "# sample to show gray scale values\n",
        "print(x_train[0][8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqkBl8O5w_lN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85f9df34-d41e-4a75-f361-e9e4acd1df6c"
      },
      "source": [
        "# sample to show labels for first train data to 10th train data\n",
        "print(y_train[0:9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwbacmBQw_r9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6a1074db-eb61-43da-b153-fbab026ab03d"
      },
      "source": [
        "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
        "print(\"every test data is \" + str(x_test.shape[1]) \n",
        "      + \" * \" + str(x_test.shape[2]) + \" image\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test data has 10000 samples\n",
            "every test data is 28 * 28 image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySA9E4Nrw_y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "aaa03e36-a75b-413c-dfa1-a19e10961a40"
      },
      "source": [
        "# Reshape\n",
        "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\", width=500, height=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM7Np--Fw_6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fbd3e004-18f6-4b85-d625-a393556d29f5"
      },
      "source": [
        "x_train = x_train.reshape(50000, 784)\n",
        "x_val = x_val.reshape(10000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J6oB0wFxAAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89f7c27c-5cff-4448-e190-29886757bd09"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ9eYK3HxUzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize data\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "gray_scale = 255\n",
        "x_train /= gray_scale\n",
        "x_val /= gray_scale\n",
        "x_test /= gray_scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B7KBHPexU5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label to one hot encoding value\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIwWPkvzxVAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7c09fdde-a9d1-47c5-f0f2-69b5fb3f2496"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n14KAUPrxVGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "578587c3-3b06-41db-ff59-22faf2d8b782"
      },
      "source": [
        "# Tensorflow MLP Graph\n",
        "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R28PIBVAxVLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li_h7TUDxVSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp(x):\n",
        "    # hidden layer1\n",
        "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
        "    b1 = tf.Variable(tf.zeros([256]))\n",
        "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "    # hidden layer2\n",
        "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
        "    b2 = tf.Variable(tf.zeros([128]))\n",
        "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
        "    # output layer\n",
        "    w3 = tf.Variable(tf.random_uniform([128,10]))\n",
        "    b3 = tf.Variable(tf.zeros([10]))\n",
        "    logits= tf.matmul(h2, w3) + b3\n",
        "    \n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2msYcs5yC01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "71fa4a4b-5b9e-49ce-93a8-d14b681d83f6"
      },
      "source": [
        "logits = mlp(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmXg0PLoyC6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits=logits, labels=y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ-6_UgqyDAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1tIf6M0yDFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "bb0d6e48-f609-4929-a99e-4d247220df9c"
      },
      "source": [
        "# Early Stopping\n",
        "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/early_stop.png\", width=500, height=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/early_stop.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwb7_QKxVX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Add ops to save and restore all the variables.\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# train hyperparameters\n",
        "epoch_cnt = 300\n",
        "batch_size = 1000\n",
        "iteration = len(x_train) // batch_size\n",
        "\n",
        "earlystop_threshold = 5\n",
        "earlystop_cnt = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhCSAN1WxAHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb1a1cf1-8333-406c-fa20-a80a3c7cde2c"
      },
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    prev_train_acc = 0.0\n",
        "    max_val_acc = 0.0\n",
        "    \n",
        "    for epoch in range(epoch_cnt):\n",
        "        avg_loss = 0.\n",
        "        start = 0; end = batch_size\n",
        "        \n",
        "        for i in range(iteration):\n",
        "            _, loss = sess.run([train_op, loss_op], \n",
        "                               feed_dict={x: x_train[start: end], y: y_train[start: end]})\n",
        "            start += batch_size; end += batch_size\n",
        "            # Compute train average loss\n",
        "            avg_loss += loss / iteration\n",
        "            \n",
        "        # Validate model\n",
        "        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "        # Calculate accuracy\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        # train accuracy\n",
        "        cur_train_acc = accuracy.eval({x: x_train, y: y_train})\n",
        "        # validation accuarcy\n",
        "        cur_val_acc = accuracy.eval({x: x_val, y: y_val})\n",
        "        # validation loss\n",
        "        cur_val_loss = loss_op.eval({x: x_val, y: y_val})\n",
        "        \n",
        "        print(\"epoch: \"+str(epoch)+\n",
        "              \", train acc: \" + str(cur_train_acc) +\n",
        "              \", val acc: \" + str(cur_val_acc) )\n",
        "              #', train loss: '+str(avg_loss)+\n",
        "              #', val loss: '+str(cur_val_loss))\n",
        "        \n",
        "        if cur_val_acc < max_val_acc:\n",
        "            if cur_train_acc > prev_train_acc or cur_train_acc > 0.99:\n",
        "                if earlystop_cnt == earlystop_threshold:\n",
        "                    print(\"early stopped on \"+str(epoch))\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"overfitting warning: \"+str(earlystop_cnt))\n",
        "                    earlystop_cnt += 1\n",
        "            else:\n",
        "                earlystop_cnt = 0\n",
        "        else:\n",
        "            earlystop_cnt = 0\n",
        "            max_val_acc = cur_val_acc\n",
        "            # Save the variables to file.\n",
        "            save_path = saver.save(sess, \"model/model.ckpt\")\n",
        "        prev_train_acc = cur_train_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, train acc: 0.12164, val acc: 0.1198\n",
            "epoch: 1, train acc: 0.81214, val acc: 0.8376\n",
            "epoch: 2, train acc: 0.85438, val acc: 0.8679\n",
            "epoch: 3, train acc: 0.8727, val acc: 0.8882\n",
            "epoch: 4, train acc: 0.8781, val acc: 0.8891\n",
            "epoch: 5, train acc: 0.8843, val acc: 0.8925\n",
            "epoch: 6, train acc: 0.88408, val acc: 0.8926\n",
            "epoch: 7, train acc: 0.891, val acc: 0.8965\n",
            "epoch: 8, train acc: 0.89956, val acc: 0.9076\n",
            "epoch: 9, train acc: 0.86904, val acc: 0.8771\n",
            "epoch: 10, train acc: 0.91334, val acc: 0.9144\n",
            "epoch: 11, train acc: 0.9173, val acc: 0.9201\n",
            "epoch: 12, train acc: 0.91158, val acc: 0.9166\n",
            "epoch: 13, train acc: 0.9071, val acc: 0.9102\n",
            "epoch: 14, train acc: 0.89238, val acc: 0.9\n",
            "epoch: 15, train acc: 0.90792, val acc: 0.9076\n",
            "overfitting warning: 0\n",
            "epoch: 16, train acc: 0.82216, val acc: 0.8295\n",
            "epoch: 17, train acc: 0.88752, val acc: 0.894\n",
            "overfitting warning: 0\n",
            "epoch: 18, train acc: 0.91514, val acc: 0.9209\n",
            "epoch: 19, train acc: 0.92052, val acc: 0.9222\n",
            "epoch: 20, train acc: 0.92458, val acc: 0.9228\n",
            "epoch: 21, train acc: 0.92304, val acc: 0.9195\n",
            "epoch: 22, train acc: 0.92478, val acc: 0.9193\n",
            "overfitting warning: 0\n",
            "epoch: 23, train acc: 0.92066, val acc: 0.9156\n",
            "epoch: 24, train acc: 0.9171, val acc: 0.9133\n",
            "epoch: 25, train acc: 0.89932, val acc: 0.8949\n",
            "epoch: 26, train acc: 0.91528, val acc: 0.9107\n",
            "overfitting warning: 0\n",
            "epoch: 27, train acc: 0.91226, val acc: 0.9063\n",
            "epoch: 28, train acc: 0.91606, val acc: 0.9097\n",
            "overfitting warning: 0\n",
            "epoch: 29, train acc: 0.9214, val acc: 0.9122\n",
            "overfitting warning: 1\n",
            "epoch: 30, train acc: 0.92862, val acc: 0.9197\n",
            "overfitting warning: 2\n",
            "epoch: 31, train acc: 0.90996, val acc: 0.9004\n",
            "epoch: 32, train acc: 0.91052, val acc: 0.9025\n",
            "overfitting warning: 0\n",
            "epoch: 33, train acc: 0.92314, val acc: 0.9156\n",
            "overfitting warning: 1\n",
            "epoch: 34, train acc: 0.93352, val acc: 0.9201\n",
            "overfitting warning: 2\n",
            "epoch: 35, train acc: 0.93218, val acc: 0.9202\n",
            "epoch: 36, train acc: 0.93504, val acc: 0.9233\n",
            "epoch: 37, train acc: 0.92854, val acc: 0.9155\n",
            "epoch: 38, train acc: 0.942, val acc: 0.9307\n",
            "epoch: 39, train acc: 0.9416, val acc: 0.9283\n",
            "epoch: 40, train acc: 0.90456, val acc: 0.8971\n",
            "epoch: 41, train acc: 0.93804, val acc: 0.9259\n",
            "overfitting warning: 0\n",
            "epoch: 42, train acc: 0.94776, val acc: 0.9301\n",
            "overfitting warning: 1\n",
            "epoch: 43, train acc: 0.95432, val acc: 0.9369\n",
            "epoch: 44, train acc: 0.9421, val acc: 0.9283\n",
            "epoch: 45, train acc: 0.95562, val acc: 0.938\n",
            "epoch: 46, train acc: 0.9564, val acc: 0.9417\n",
            "epoch: 47, train acc: 0.96352, val acc: 0.9428\n",
            "epoch: 48, train acc: 0.96346, val acc: 0.94\n",
            "epoch: 49, train acc: 0.96322, val acc: 0.9424\n",
            "epoch: 50, train acc: 0.96418, val acc: 0.94\n",
            "overfitting warning: 0\n",
            "epoch: 51, train acc: 0.95626, val acc: 0.9332\n",
            "epoch: 52, train acc: 0.95764, val acc: 0.9353\n",
            "overfitting warning: 0\n",
            "epoch: 53, train acc: 0.951, val acc: 0.9317\n",
            "epoch: 54, train acc: 0.95582, val acc: 0.9346\n",
            "overfitting warning: 0\n",
            "epoch: 55, train acc: 0.9573, val acc: 0.9356\n",
            "overfitting warning: 1\n",
            "epoch: 56, train acc: 0.94704, val acc: 0.9264\n",
            "epoch: 57, train acc: 0.9548, val acc: 0.9316\n",
            "overfitting warning: 0\n",
            "epoch: 58, train acc: 0.95728, val acc: 0.935\n",
            "overfitting warning: 1\n",
            "epoch: 59, train acc: 0.96678, val acc: 0.944\n",
            "epoch: 60, train acc: 0.96688, val acc: 0.9458\n",
            "epoch: 61, train acc: 0.96668, val acc: 0.9441\n",
            "epoch: 62, train acc: 0.9635, val acc: 0.94\n",
            "epoch: 63, train acc: 0.97292, val acc: 0.9469\n",
            "epoch: 64, train acc: 0.97042, val acc: 0.9486\n",
            "epoch: 65, train acc: 0.9833, val acc: 0.9552\n",
            "epoch: 66, train acc: 0.98072, val acc: 0.9525\n",
            "epoch: 67, train acc: 0.97318, val acc: 0.9481\n",
            "epoch: 68, train acc: 0.97584, val acc: 0.9518\n",
            "overfitting warning: 0\n",
            "epoch: 69, train acc: 0.97992, val acc: 0.9541\n",
            "overfitting warning: 1\n",
            "epoch: 70, train acc: 0.9777, val acc: 0.9546\n",
            "epoch: 71, train acc: 0.97312, val acc: 0.9501\n",
            "epoch: 72, train acc: 0.97618, val acc: 0.9509\n",
            "overfitting warning: 0\n",
            "epoch: 73, train acc: 0.9638, val acc: 0.9381\n",
            "epoch: 74, train acc: 0.97084, val acc: 0.9444\n",
            "overfitting warning: 0\n",
            "epoch: 75, train acc: 0.98464, val acc: 0.9585\n",
            "epoch: 76, train acc: 0.98762, val acc: 0.9596\n",
            "epoch: 77, train acc: 0.98744, val acc: 0.9572\n",
            "epoch: 78, train acc: 0.98828, val acc: 0.9589\n",
            "overfitting warning: 0\n",
            "epoch: 79, train acc: 0.99148, val acc: 0.9615\n",
            "epoch: 80, train acc: 0.98572, val acc: 0.954\n",
            "epoch: 81, train acc: 0.9865, val acc: 0.9545\n",
            "overfitting warning: 0\n",
            "epoch: 82, train acc: 0.99398, val acc: 0.9606\n",
            "overfitting warning: 1\n",
            "epoch: 83, train acc: 0.99042, val acc: 0.9566\n",
            "overfitting warning: 2\n",
            "epoch: 84, train acc: 0.9946, val acc: 0.9622\n",
            "epoch: 85, train acc: 0.99062, val acc: 0.9583\n",
            "overfitting warning: 0\n",
            "epoch: 86, train acc: 0.98916, val acc: 0.9555\n",
            "epoch: 87, train acc: 0.99758, val acc: 0.9655\n",
            "epoch: 88, train acc: 0.99628, val acc: 0.9632\n",
            "overfitting warning: 0\n",
            "epoch: 89, train acc: 0.99892, val acc: 0.9652\n",
            "overfitting warning: 1\n",
            "epoch: 90, train acc: 0.9997, val acc: 0.9674\n",
            "epoch: 91, train acc: 0.99976, val acc: 0.9667\n",
            "overfitting warning: 0\n",
            "epoch: 92, train acc: 0.99976, val acc: 0.9671\n",
            "overfitting warning: 1\n",
            "epoch: 93, train acc: 0.99988, val acc: 0.9671\n",
            "overfitting warning: 2\n",
            "epoch: 94, train acc: 0.99946, val acc: 0.9665\n",
            "overfitting warning: 3\n",
            "epoch: 95, train acc: 0.99986, val acc: 0.9666\n",
            "overfitting warning: 4\n",
            "epoch: 96, train acc: 0.99988, val acc: 0.9669\n",
            "early stopped on 96\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}